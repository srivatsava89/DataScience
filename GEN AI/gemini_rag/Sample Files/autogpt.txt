
14
Auto-GPT for Online Decision Making: Benchmarks and Additional Opinionsmaking autonomous decisions. However, by introducingopinions from various weak learners, GPT4 can enhance itsperformance. Considering these diverse viewpoints may al-low GPT4 to mitigate its own biases and overcome inherentlimitations.Interestingly, the inclusion of a single IL choice as an ad-ditional opinion in the context resulted in improved perfor-mance for all LLMs. This performance boost is particularlynoteworthy for GPT4, because GPT4 by itself outperformsthe additional opinions provided by IL models, while stillbenefiting from this method.To explore the impact of single vs. multiple additionalopinions, we also tested sampled top five additional opin-ions vs. one (see Table 1), and observed GPT4 with top 5additional opinions reached the best Success Rate, Rewardsand Precision across all groups (Table 1). From an intelligentagent perspective, awareness of an additional opinion, oreven multiple distinct opinions, can be beneficial, as arguedin [23]. This suggests that providing LLMs with one or afew additional opinions of reasonable quality can serve as areference, resulting in a more informed decision.Out of curiosity, we also conducted one ablation studyby providing random one additional opinion to GPT3.5. Weobserved the worst performance - the lowest reward (22.333)and an equivalently low success rate (0.060) as Rule basedmodel.In Figure 2, we observe that Language Learning Models(LLMs) predominantly take in the additional opinion sug-gested by expert models, with GPT4 exhibiting the higheststandard and the greatest proportion of disagreements. Weconsider any match among the top 5 additional opinionsas being taken into account by the LLMs. Intriguingly, forGPT4, the ratio of considered opinions escalates from 0.549to 0.602 as the number of opinions increases from 1 to 5.This trend could partially elucidate the disparity in the finaloutcomes of success rates.3.4.2ALFWorld.Taking inspiration from our previous Web-shop experiment, we employed a similar paradigm to com-bine Large Language Models (LLMs) with Expert modelsin the context of the ALFWorld dataset. The fundamentalpremise remained analogous, but due to resource constraintsand the extensive size of ALFWorld (134 unseen games), weconfined our initial trial to a top 1 Imitation Learning (IL)opinion.Our hypothesis received empirical confirmation from thedata observed for GPT4 and Claude, as detailed in Table2. The success rate showed slight improvements, althoughthe original DAgger agent provided by ALFWorld was lesseffective for general tasks compared to specific ones, asdemonstrated by the task-specific performance rates listedin Table 4 from the ALFWorld paper [19], i.e in a disparateperformance range, the DAgger agent excelled in the ’Cooland Place’ task, achieving a remarkable 1.00 success rate.However, for the ’Pick Two and Place’ task, its proficiencywas considerably lower, with a success rate of only 0.24.Our investigation further revealed a substantial variancein efficiency concerning the number of steps taken by theALFWorld IL model to complete tasks. This observationhighlights an additional layer of complexity, suggesting thatFigure 2: For Webshop, the ratios of LLMs consideringor disagreeing with additional opinion provided byexpert models. For the top 5 scenario, we consider itas an agreement if any additional opinion matches.the IL’s performance is not only variable in terms of tasksuccess rates, but also in the practical efficiency of task ex-ecution. This large variability in step numbers indicatesthat while the IL model may excel in some tasks, it can bemarkedly inefficient in others, further reinforcing the in-herent limitations and variability of IL models in complextask simulations like ALFWorld. In terms of task completion,the IL’s outcomes are governed by real-time rewards. Assuch, all completed tasks have to be executed correctly, asevidenced by 1.00 precision for the both IL with and withoutBeam Search. Conversely, the tasks left incomplete weretypically ones where the agent had exhausted the availablesteps, with most of these marked by repeated and meaning-less actions as presented in Appendix 2.One of the standout observations from our study wasGPT4’s ability to integrate past memories, task descriptions,and environmental data to discern the pertinence of sugges-tions from the IL model. Even amidst noise, GPT4 demon-strated a robust capacity to differentiate beneficial fromirrelevant advice, often confidently disregarding sugges-tions that were not beneficial, as illustrated in Appendix 3.Moreover, GPT4 was even able to extract values from theinitial part of a repetitive action pattern suggested by the IL,underscoring its exceptional ability to distill useful informa-tion. Contrastingly, GPT3.5 was easily misled by irrelevantsuggestions and frequently became entangled in the repeti-tive advice offered by the IL. Indeed, such confusion evencompromised GPT3.5’s capability to perform tasks that itcould otherwise successfully accomplish independently, asdetailed in Appendix 4. This highlights a stark divergencefrom the patterns observed with GPT4 under ALFWorldContext.In a compelling revelation, this study demonstrated amarked difference between the contexts of the Webshop
and ALFWorld experiments. The beneficial guidance pro-vided by the Webshop’s IL model effectively condensed thechoice spaces for LLMs, contrasted with the repetitive andmisleading advice offered by the IL in the ALFWorld con-text. Interesting discrepancies were also observed in howthe LLMs disagreed with the IL’s recommendations: Clauderegistered a disagreement rate of 0.814, GPT3.5 of 0.769,and GPT4, leading the pack, registered a rate of 0.854. Thissuggests an inherent capability within LLMs to filter outmisleading suggestions. However, the extent to which thisdisagreement improved or impeded performance appearedto be context-dependent, highlighting the importance of dis-cernment in processing the IL’s advice. Claude and speciallyGPT4 showed remarkable adeptness at avoiding the pitfallsof misleading and repetitive advice. By contrast, GPT3.5exhibited a clear shortfall in this respect, a performanceechoed by its pairing with a random action in our Webshopablation study. This underscores the importance of contextwhen integrating IL models with LLMs and signals the needfor careful evaluation when dealing with potentially mis-leading input, especially on an LLM like GPT3.5 which canget easily confused.Figure 3: For ALFWorld, the ratios of LLMs consideringor disagreeing with additional opinion provided byexpert models. For the top 1 case, we only redeem itas an agreement if the exact opinion matches.3.5  DiscussionsInitially, Auto-GPT was conceptualized as an experimentalidea rather than a robust workflow suitable for real-worldapplications. However, our research demonstrates otherwise.Auto-GPT not only proves its potential for practical usebut also outperforms supervised state-of-the-art IL modelswith GPT4, signifying a shift in perspective towards thisinnovative approach.In the current discourse, we posit that this additional opin-ion approach can readily find widespread adoption acrossdiverse industries, given the existing prevalence of expertmodels such as recommendation systems and traditionalnatural language processing (NLP) services, inclusive of textclassification models and the like. An immediate applica-tion for this methodology can be envisaged in leveragingLLMs for making definitive determinations and give explana-tions regarding the prioritization of items, such as movies orsongs, to be displayed to the user. This is achievable by pro-viding the selected top-k outputs derived from a supervisedrecommendation model to LLMs as Additional Opinions.It is crucial to note, however, that the two tasks we havechosen to benchmark in this research do not fully encapsu-late the vast array of potential real-world scenarios. Theyserve merely as a starting point for the exploration of thisidea. This is the inaugural instance where the concept ofadapting Auto-GPT to handle complex tasks by introduc-ing Additional Opinions has been proposed. This innova-tive approach opens new avenues for further research anddevelopment, potentially expanding the realm of practicalapplications for AI models and significantly impacting ourunderstanding of complex decision-making mechanisms.4  RELATED WORKFoundation models trained on self-supervision tasks haveshown significant success in downstream tasks, particu-larly in few-shot and zero-shot settings [5,7,10]. Morerecently, generative pre-trained foundation models havedemonstrated impressive in-context learning abilities, al-lowing them to tackle decision-making tasks that requirelogic reasoning [8] and/or interactions with external APIs[9,13,22]. However, adapting LLMs for decision-makingtasks often involves non-trivial prompt design, memory re-trieval mechanisms to dynamically construct the agent’scontext [12,17,25], and sometimes model fine-tuning [9]to enhance its decision-making abilities.Several techniques have been proposed to adapt LargeLanguage Models (LLMs) for improved planning and rea-soning. These include methods for enabling explicit Chainof Thought (CoT) thinking processes [21], as well as prompt-ing and decoding techniques aimed at enhancing the self-consistency of LLMs [6,20]. However, most of these tech-niques primarily focus on offline reasoning tasks that can beplanned ahead, while their implications in online decision-making scenarios are rarely discussed.5  CONCLUSIONOur experimental results highlight the successful adaptationof the Auto-GPT styled agent to complex online decision-making tasks through straightforward prompt design, sur-passing IL-based baseline models specifically designed forthese tasks. Among the foundational LLMs powering Auto-GPT, GPT-4 demonstrates superior performance. Addition-ally,  we  introduce  an  innovative  strategy  of  incorporat-ing additional opinions from external expert models, fur-ther enhancing the decision-making capabilities of Auto-GPT styled agents, particularly benefiting GPT-4. Our Addi-tional Opinions algorithm provides a lightweight supervisedtraining approach for Auto-GPT styled agents, enablingimproved performance without requiring extensive fine-tuning of the LLMs. We demonstrate the effectiveness and
Auto-GPT for Online Decision Making: Benchmarks and Additional Opinionsadaptability of this approach, especially for tasks with eas-ily collectible training data for action policy. The code of thiswork is shared in: https://github.com/younghuman/LLMAgentREFERENCES[1]Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, JacksonKernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, andCameron McKinnon. 2022. Constitutional AI: Harmlessness from AIFeedback. InarXiv:2212.08073. arXiv.  https://ar5iv.org/abs/2212.08073[2]Sébastien   Bubeck,   Varun   Chandrasekaran,   Ronen   Eldan,   Jo-hannes   Gehrke,   Eric   Horvitz,   Ece   Kamar,   Peter   Lee,   Yin   TatLee,  Yuanzhi  Li,  Scott  Lundberg,  Harsha  Nori,  Hamid  Palangi,Marco  Tulio  Ribeiro,  and  Yi  Zhang.  2023.Sparks  of  ArtificialGeneral Intelligence: Early experiments with GPT-4. (March 2023).https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/[3]Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma,Gaurav  Mishra,  Adam  Roberts,  Paul  Barham,  Hyung  Won  Chung,Charles Sutton, Sebastian Gehrmann, et al.2022. Palm: Scaling languagemodeling with pathways.arXiv preprint arXiv:2204.02311(2022).[4]Marc-Alexandre Côté, Ákos Kádár, Xingdi Yuan, Ben Kybartas, TavianBarnes, Emery Fine, James Moore, Matthew Hausknecht, Layla El Asri,Mahmoud Adada, et al.2018. Textworld: A learning environment fortext-based games. (2018), 41–75.[5]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.2018. Bert: Pre-training of deep bidirectional transformers for languageunderstanding.arXiv preprint arXiv:1810.04805(2018).[6]Yao  Fu,  Hao  Peng,  Ashish  Sabharwal,  Peter  Clark,  and  TusharKhot. 2023.  Complexity-Based Prompting for Multi-Step Reasoning.arXiv:2210.00720 [cs.CL][7]Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel,Piyush  Sharma,  and  Radu  Soricut.  2019.Albert:  A  lite  bert  forself-supervised learning of language representations.arXiv preprintarXiv:1909.11942(2019).[8]Yang Li, Zhi-Ping Cai, and Hong Xu. 2018.  LLMP: exploiting LLDPfor latency measurement in software-defined data center networks.Journal of Computer Science and Technology33 (2018), 277–285.[9]Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu,Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, et al.2023. Taskmatrix. ai:Completing tasks by connecting foundation models with millions ofapis.arXiv preprint arXiv:2303.16434(2023).[10]Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, DanqiChen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.2019. Roberta: A robustly optimized bert pretraining approach.arXivpreprint arXiv:1907.11692(2019).[11]   OpenAI. 2023. GPT-4 Technical Report.  arXiv:2303.08774 [cs.CL][12]Joon Sung Park, Joseph C. O’Brien, Carrie Cai, Meredith Ringel Morris,Percy Liang, and Michael Bernstein. 2023. Generative Agents: Interac-tive Simulacra of Human Behavior.  https://arxiv.org/pdf/2304.03442.pdf[13]Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez.2023.  Gorilla: Large Language Model Connected with Massive APIs.arXiv:2305.15334 [cs.CL][14]Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and JianfengGao. 2022.Instruction Tuning with GPT-4.  https://ar5iv.org/abs/2304.03277[15]Stephane Ross, Geoffrey J. Gordon, and J. Andrew Bagnell. 2011.  AReduction of Imitation Learning and Structured Prediction to No-RegretOnline Learning.arXiv preprint arXiv:1011.0686(2011). arXiv:1011.0686[16]Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, andYueting Zhuang. 2023. HuggingGPT: Solving AI Tasks with ChatGPTand its Friends in HuggingFace.  arXiv:2303.17580 [cs.CL][17]Noah Shinn, Beck Labash, and Ashwin Gopinath. 2023. Reflexion: anautonomous agent with dynamic memory and self-reflection.arXivpreprint arXiv:2303.11366(2023).[18]Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Win-son Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. 2020.ALFRED: A Benchmark for Interpreting Grounded Instructions forEveryday Tasks.arXiv preprint arXiv:1912.01734(2020).[19]Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk,Adam Trischler, and Matthew Hausknecht. 2021.   Alf World: Align-ing Text and Embodied Environments for Interactive Learning.arXivpreprint arXiv:2010.03768(2021).[20]Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sha-ran Narang, Aakanksha Chowdhery, and Denny Zhou. 2023.   Self-Consistency Improves Chain of Thought Reasoning in Language Mod-els.  arXiv:2203.11171 [cs.CL][21]Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi,Quoc Le, and Denny Zhou. 2022. Chain of thought prompting elicitsreasoning in large language models.arXiv preprint arXiv:2201.11903(2022).[22]Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, Pieter Abbeel, and DaleSchuurmans. 2023. Foundation Models for Decision Making: Problems,Methods, and Opportunities.arXiv e-prints(2023), arXiv–2303.[23]Ilan Yaniv. 2004. The benefit of additional opinions.Current directionsin psychological science13, 2 (2004), 75–78.[24]Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. 2022.Webshop: Towards scalable real-world web interaction with groundedlanguage agents.arXiv preprint arXiv:2207.01206(2022).[25]Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, KarthikNarasimhan, and Yuan Cao. 2022.  React: Synergizing reasoning andacting in language models.arXiv preprint arXiv:2210.03629(2022).A  APPENDIX
A.1  APPENDIX 1. Webshop: Evidence of GPT-4 considering additional opinion.A.1.1    Example 1. Webshop: AutoGPT(GPT-4) disagreed with the Additional Opinion.[breaklines]Command search returned: =Observation=Instruction:i want a pink niuta 2 pack hair towel wrap for dry hair, and price lower than 20.00 dollars[button] Back to Search [button_]Page 1 (Total results: 50)[button] Next > [button_][button] B08G14B779 [button_]NIUTA 2 Pack Hair Towel Wrap, Microfiber Quick Drying Hair Towels, Super Absorbent Quick Dry Hair Towel,Wrapped Bath Cap (Pink+Light Blue)$4.99[button] B092QTHX2Z [button_]Microfiber Hair Towel Wrap POPCHOSE Ultra Absorbent, Fast Drying Hair Turban Soft, No Frizz Hair Wrap Towels for Women Wet Hair,Curly, Longer, Thicker Hair. . .$8.99[button] B08NX5S6S2 [button_]Microfiber Hair Towel Wrap for Women Super Absorbent Quick Dry Hair Towels with Button Design for Drying Curly&Thick Hair 2Pack(Purple+Camel)$8.99[button] B09KKCQ7FK [button_]VOLO Hero Microfiber Hair Towel, Super Absorbent, Ultra-Soft, Fast Drying | Reduce Dry Time by 50%, Large, Premium Wrap Towel,Sustainable Packaging, Anti-Frizz | Luna Gray (2 Pack)$70.0[button] B083FPQ77W [button_]Microfiber Hair Towels Super Absorbent Hair Drying Towel Turban for Women and Girls Quick Magic Hair Dry Hat Hair Towel Wrap BathingWrapped Cap 2 Packs (Pink+Grey)$13.99[button] B09KK4GZW1 [button_]VOLO Hero Microfiber Hair Towel | Super Absorbent, Ultra-Soft, Fast Drying | Reduce Dry Time by 50% | Large, Premium Wrap Towel forAll Hair Types | Anti-Frizz, Anti-Breakage | Luna Gray (2 Pack)$78.0[button] B074T227KV [button_]Microfiber Hair Towel, 2 Pack Dry Hair Towel Twist Wrap Absorbent Quickly Dry Hair Towel for Kids and Women (Pink+Purple)$10.97[button] B08CZBMHDR [button_]Hair Towel Wrap, [2 Pack] Microfiber Quick Dry Hair Turban Wrap - Super Absorbent,Microfiber Hair Towel with Button,Quick DryHair Towel for Women,Hair Turbans for Wet Hair,Wrapped Bath Cap(Pink Blue)$10.99[button] B09FB25N5V [button_]SYMGILA Microfiber Hair Towel Wrap, Hair Turbans for Wet Hair, Drying Hair Wrap Towels for Curly Hair Women Anti Frizz 2 Pack(Blue/Beige)$100.0[button] B08YMYXBK8 [button_]VOLO Hero Microfiber Hair Towel, Super Absorbent, Ultra-Soft, Fast Drying | Reduce Dry Time by 50%, Large, Premium Wrap Towel,Sustainable Packaging, Anti-Frizz, Anti-Breakage, Hands-Free (Luna Gray)$34.99loop number:2Here's one suggestion for the command: click with'back to search'.Please use this suggestion as a reference and make your own judgement. Determine which next command to use, and respondusing the JSON format specified above:{"thoughts": {"text": "I found the matching item with a price lower than $20.","reasoning": "The first item (B08G14B779) matches the description and has a price of $4.99, which is lower than $20.","plan": "- click on the matching item (B08G14B779)\n- review the item details\n- make the purchase","criticism": "Clicking'back to search'is not necessary since I already found the matching item."},"command": {"name": "click","args": {"tool_input": "B08G14B779"}}}
Auto-GPT for Online Decision Making: Benchmarks and Additional OpinionsA.1.2    Example 2. Webshop: AutoGPT(GPT-4) agreed with the Additional Opinion.[breaklines,fontsize=\footnotesize]{text}Command search returned: =Observation=Instruction:i want to buy a folding storage box ottoman which i can easily install and has faux leather, the size of it should be 60x40x40cm,and price lower than 160.00 dollars[button] Back to Search [button_]Page 1 (Total results: 50)[button] Next > [button_][button] B09LYXGGDD [button_]Storage Stool Faux Leather Pouffe Folding Storage Ottoman Footstool Box Toy Chest with Lid, Foldable Foot Stool Seat for Living Room,Bedroom (Pink,15.7x15.7x15.7in) Footstool Sofa Stool$274.66[button] B09LYZ12DH [button_]Storage stool Folding Ottoman Storage Bench Cube Hold up 881lbs Faux Leather Long Chest with Memory Foam Seat Footrest PaddedUpholstered Stool for Bedroom Box Bed Coffee Table Rectangular Purple Foot$344.02[button] B09NXSRVSK [button_]Storage stool Folding Ottoman Storage Bench Cube Hold up 881lbs Faux Leather Long Chest with Memory Foam Seat Footrest PaddedUpholstered Stool for Bedroom Box Bed Coffee Table Rectangular Brown (Size$408.25[button] B09NXP95GC [button_]Storage stool Storage Ottoman Bench, Foldable Footrest Shoe Bench with Large Space, End of Bed Storage Seat, Storage Stool Box ToyChest Support 881lbs, Faux Leather fabric (Colourl:Orange,Size:40x40x$139.42[button] B09NTCCVGX [button_]Ottoman Footstools Folding Storage Box with Lid, Large Storage Seat Faux Leather Footstool Toy Storage Box, Yellow, 40x40x40cm (Color :Yellow, Size : 40X40X40cm)$149.97[button] B09NXRK5MX [button_]Storage stool Faux Leather Folding Organizer Storage Ottoman Bench Cube Foot Stool, Footrest Step Stool for Living Room, Bedroom,Office, Garden, Traveling, Fishing, Camping 15.7"x15.7"x15.7" (Purple)$150.01[button] B09NTFLKXR [button_]Folding Storage Ottoman Bench,Storage Chest Footrest Padded Seat,Faux Leather Ottoman Foot Rest Stool for Bedroom(Colour: Black,Size:40x40x40cm/15.7x15.7x15.7in) (Color : Black, Size : 60X40X40cm)$181.34[button] B09MYV58YY [button_]QTQHOME Rectangular Faux Leather Storage Ottoman Bench,Modern Tufted Storage Bench with Metal Leg,Upholstered Shoe Bench for LivingRoom Entryway Bedroom-Orange 60x40x40cm(24x16x16inch)$100.0[button] B08F3LZKSB [button_]YZZSJC Storage Stool Foot Stool Rest Ottoman Storage Boxes, Cloth Shoe Changing Stool Storage Box Minimalist Clothing Store Sofa Stool(Color : Light Blue, Size : 60x40x40cm)$264.04[button] B089D5K8LY [button_]XMZDDZ Ottoman Storage Seat Bench,Faux Leather Tufted Storage Bench Footrest Stool with Padded Seat,Rectangular Bed Bench for EntrywayBedroom Pink 60x40x40cm(24x16x16in)$100.0loop number:2Here's one suggestion for the command: click with'b09nxp95gc'.Please use this suggestion as a reference and make your own judgement. Determine which next command to use, and respond using the JSONformat specified above:{"thoughts": {"text": "I need to click on the item B09NXP95GC.","reasoning": "The item B09NXP95GC matches the size, material, and price requirements.","plan": "- click on the item\n- review the item details\n- make the purchase","criticism": "N/A"},"command": {"name": "click","args": {"tool_input": "B09NXP95GC"}}}
A.2  APPENDIX 2. ALFWorld: Evidence of ALFWorld DAgger AgentA.2.1    Example 1. ALFWorld: DAgger Agent repeated actions for "pick and place" task.[breaklines,fontsize=\footnotesize]{text}pick_and_place_simple-PepperShaker-None-Drawer-10look | go to cabinet 4 | go to cabinet 4 | go to cabinet 4 | go to cabinet 1 | go to cabinet 4 | go to cabinet 4 | go to cabinet 4 | go tocabinet 4 | go to cabinet 4 | go to cabinet 3 | take saltshaker 1 from cabinet 3 | go to drawer 3 | open drawer 3 | put saltshaker 1 in/on drawer3 | close drawer 3 | go to cabinet 2 | open cabinet 2 | close cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 |go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 |go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 |go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 | go to cabinet 2 |go to cabinet 2 | go to cabinet 2 | go to cabinet 2pick_and_place_simple-Watch-None-Safe-219look | go to shelf 2 | go to shelf 1 | go to shelf 1 | go to shelf 1 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go toshelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12| go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go toshelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12| go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go toshelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12 | go to shelf 12pick_and_place_simple-Mug-None-Desk-308look | go to shelf 5 | go to shelf 2 | go to shelf 2 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go toshelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go toshelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go toshelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go toshelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go toshelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5 | go to shelf 5A.2.2    Example 2. ALFWorld: DAgger Agent effective action for "pick clean then place" task.[breaklines,fontsize=\footnotesize]{text}pick_clean_then_place_in_recep-Cloth-None-CounterTop-424look | go to cabinet 1 | open cabinet 1 | close cabinet 1 | go to countertop 1 | take cloth 3 from countertop 1 | go to sinkbasin 1 | clean cloth3 with sinkbasin 1 | go to countertop 1 | put cloth 3 in/on countertop 1 | --pick_clean_then_place_in_recep-Pan-None-CounterTop-1look | go to countertop 1 | take pan 1 from countertop 1 | go to sinkbasin 1 | clean pan 1 with sinkbasin 1 | go to countertop 3 | put pan 1in/on countertop 3 | --pick_clean_then_place_in_recep-Spatula-None-Drawer-10look | go to countertop 3 | take spatula 1 from countertop 3 | go to sinkbasin 1 | clean spatula 1 with sinkbasin 1 | go to drawer 2 | opendrawer 2 | put spatula 1 in/on drawer 2 | --
Auto-GPT for Online Decision Making: Benchmarks and Additional OpinionsA.3  APPENDIX 3. ALFWorld: Evidence of GPT-4 considering additional opinion.A.3.1    Example 1. ALFWorld: AutoGPT(GPT-4) disagreed with the Additional Opinion.[breaklines,fontsize=\footnotesize]{text}Instruction:You are in the middle of a room. Looking quickly around you, you see a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a countertop 1, agarbagecan 1, a handtowelholder 2, a handtowelholder 1, a sinkbasin 2, a sinkbasin 1, a toilet 1, a toiletpaperhanger 1, and a towelholder 1.Yourtask is to: clean some soapbar and put it in countertop.After you go to countertop 1, current observation is: On the countertop 1, you see a soapbar 1, and a spraybottle 1.Available Actions are:action] examine countertop 1 [action_][action] go to cabinet 1 [action_][action] go to cabinet 2 [action_][action] go to cabinet 3 [action_][action] go to cabinet 4 [action_][action] go to garbagecan 1 [action_][action] go to handtowelholder 1 [action_][action] go to handtowelholder 2 [action_][action] go to sinkbasin 1 [action_][action] go to sinkbasin 2 [action_][action] go to toilet 1 [action_][action] go to toiletpaperhanger 1 [action_][action] go to towelholder 1 [action_][action] inventory [action_][action] look [action_][action] take soapbar 1 from countertop 1 [action_][action] take spraybottle 1 from countertop 1 [action_]HumanMessage(content='Here's one suggestion for the command: ['put handtowel 1 in/on countertop 1'].Please use this suggestion as a reference and make your own judgement. Determine which next command to use, and respond using the JSON formatspecified above:')AIMessage(content='{"thoughts": {"text": "...","reasoning": "The suggestion to put handtowel 1 in/on countertop 1 is not relevant to the task. I found the soapbar on countertop 1,so I should take it and proceed with cleaning it.","plan": "- Take the soapbar\\n- Clean the soapbar\\n- Put the soapbar on the countertop","criticism": "N/A."},"command": {"name": "alfworld_action","args": {"tool_input": "take soapbar 1 from countertop 1"}}}')
A.3.2    Example 2. ALFWorld: AutoGPT(GPT-4) agreed with the Additional Opinion.[breaklines,fontsize=\footnotesize]{text}Instruction:You are in the middle of a room. Looking quickly around you, you see a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a countertop 1, agarbagecan 1, a handtowelholder 2, a handtowelholder 1, a sinkbasin 2, a sinkbasin 1, a toilet 1, toiletpaperhanger 1, and a towelholder 1. Yourtask is to: clean some soapbar and put it in countertop.After you open cabinet 4, current observation is: Nothing happens.Available Actions are:[action] close cabinet 3 [action_][action] examine cabinet 3 [action_][action] go to cabinet 1 [action_][action] go to cabinet 2 [action_][action] go to cabinet 4 [action_][action] go to countertop 1 [action_][action] go to garbagecan 1 [action_][action] go to handtowelholder 1 [action_][action] go to handtowelholder 2 [action_][action] go to sinkbasin 1 [action_][action] go to sinkbasin 2 [action_][action] go to toilet 1 [action_][action] go to toiletpaperhanger 1 [action_][action] go to towelholder 1 [action_][action] inventory [action_][action] look [action_][action] take candle 1 from cabinet 3 [action_][action] take toiletpaper 3 from cabinet 3 [action_]HumanMessage(content="Here's one suggestion for the command: ['go to countertop 1'].Please use this suggestion as a reference and make your own judgement. Determine which next command to use, and respond using the JSON formatspecified above:")AIMessage(content='{"thoughts": {"text": "...","reasoning": "I have checked all the cabinets and didn\'t find a soapbar. I will now go to countertop 1 to check if there\'s a soapbarthere.","plan": "- Find and take the soapbar\\n- Clean the soapbar\\n- Put the soapbar on the countertop","criticism": "N/A."},"command": {"name": "alfworld_action","args": {"tool_input": "go to countertop 1"}}}')
Auto-GPT for Online Decision Making: Benchmarks and Additional OpinionsA.4  APPENDIX 4. ALFWorld: Evidence of GPT-3.5 confused by additional opinion.A.4.1    Example 1. ALFWorld: AutoGPT(GPT-3.5) performed the task by it’s own.[breaklines,fontsize=\footnotesize]{text}Instruction:You are in the middle of a room. Looking quickly around you, you see a bed 1, a desk 2, a desk 1, a drawer 6, a drawer 5, a drawer 4, a drawer 3,a drawer 2, a drawer 1, a garbagecan 1, a laundryhamper 1, a safe 1, a shelf 6, a shelf 5, a shelf 4, a shelf 3, a shelf 2, and a shelf 1.Yourtask is to: examine the mug with the desklamp.\nAfter you go to shelf 2, current observation is: On the shelf 2, you see a creditcard 2, and apen 2.Available Actions are:[action] examine shelf 2 [action_][action] go to bed 1 [action_][action] go to desk 1 [action_][action] go to desk 2 [action_][action] go to drawer 1 [action_][action] go to drawer 2 [action_][action] go to drawer 3 [action_][action] go to drawer 4 [action_][action] go to drawer 5 [action_][action] go to drawer 6 [action_][action] go to garbagecan 1 [action_][action] go to laundryhamper 1 [action_][action] go to safe 1 [action_][action] go to shelf 1 [action_][action] go to shelf 3 [action_][action] go to shelf 4 [action_][action] go to shelf 5 [action_][action] go to shelf 6 [action_][action] inventory [action_][action] look [action_][action] take creditcard 2 from shelf 2 [action_][action] take pen 2 from shelf 2 [action_]HumanMessage(content='Determine which next command to use, and respond using the JSON format specified above:')AIMessage(content='{"thoughts": {"text": "...","reasoning": "I need to find a mug and a desklamp. A mug is more likely to appear in shelf 1-6, desk 1-2, drawer 1-6. A desklamp is morelikely to appear in desk 1-2, shelf 1-6. I can check one by one, starting with shelf 3.","plan": "- Find a mug and a desklamp\\n- Examine the mug with the desklamp","criticism": "N/A."},"command": {"name": "alfworld_action","args": {"tool_input": "go to shelf 3"}}}')
A.4.2    Example 2. ALFWorld: AutoGPT(GPT-3.5) confused by IL repeated opinion.[breaklines,fontsize=\footnotesize]{text}Instruction:You are in the middle of a room. Looking quickly around you, you see a bed 1, a desk 2, a desk 1, a drawer 6, a drawer 5, a drawer 4, a drawer 3,a drawer 2, a drawer 1, a garbagecan 1, a laundryhamper 1, a safe 1, a shelf 6, a shelf 5, a shelf 4, a shelf 3, a shelf 2, and a shelf 1.Yourtask is to: examine the mug with the desklamp.After you go to shelf 2, current observation is: Nothing happens.Available Actions are:[action] examine shelf 2 [action_][action] go to bed 1 [action_][action] go to desk 1 [action_][action] go to desk 2 [action_][action] go to drawer 1 [action_][action] go to drawer 2 [action_][action] go to drawer 3 [action_][action] go to drawer 4 [action_][action] go to drawer 5 [action_][action] go to drawer 6 [action_][action] go to garbagecan 1 [action_][action] go to laundryhamper 1 [action_][action] go to safe 1 [action_][action] go to shelf 1 [action_][action] go to shelf 3 [action_][action] go to shelf 4 [action_][action] go to shelf 5 [action_][action] go to shelf 6 [action_][action] inventory [action_][action] look [action_][action] take creditcard 2 from shelf 2 [action_][action] take pen 2 from shelf 2 [action_]HumanMessage(content="Here's one suggestion for the command: ['go to shelf 2'].Please use this suggestion as a reference and make your own judgement. Determine which next command to use, and respond using the JSON formatspecified above:")AIMessage(content='{"thoughts": {"text": "I will use the \'alfworld_action\'command to examine shelf 2 again.","reasoning": "Since I did not find the desklamp on shelf 2, I need to examine it again to make sure I didn\'t miss          anything.","plan": "- Use the \'alfworld_action\'command to go to shelf 2.\\\\n- Examine the items on the shelf again to find the desklamp.\\\\n- Once I find the desklamp, I can use it to examine the mug.","criticism": "I should have been more thorough in my examination of shelf 2 the first time."},"command": {"name": "alfworld_action","args": {"tool_input": "go to shelf 2"}}})