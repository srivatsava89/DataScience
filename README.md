### GEN AI SQL - ASSISTANT 
------------------------

A Gen AI SQL Assistant is an AI-powered tool designed to assist users in interacting with databases through SQL (Structured Query Language) without requiring advanced SQL knowledge. This type of assistant uses natural language processing (NLP) and machine learning models to help users write, execute, and optimize SQL queries efficiently. Here are some key features and capabilities of a Gen AI SQL Assistant:

Files:
-------
-GENAI-SQL-Assistant_Hackathon.pptx :  Explains the problem statement and Architecture of the project. 
-app_secrets.py : Contains Api_keys and connection details
-genai_sql_assitant.py : Main  file to run the application.
-invalid_records.csv : Contains invalid records after data quality check.
-kafka-connector_test.py : Its used for testing purpose, to test the code in multiple ways. 
-prompts.txt : Contains the prompts for Generative Ai to produce the queries efficiently.
-requirement.txt : Contains all the libraries required to run the application. 
-sampledata.txt : contains Json data for tables which are created. 

===========================================================================================================

## 1. Install required Librabries : 
-----------------------------------

pip install -r requirement.txt

##1.1 Secrets
-------------

Add required secrets in app_secrets.py

=========================================================================================================
## 2. Running the App:

streamlit run genai_sql_assistant.py

=========================================================================================================
## 3. Navigating the App:

Query Data Tab: Type a query or prompt, and the app will generate SQL through Google Gemini, fetch the corresponding data from Snowflake, and display it.

Data Catalog Tab: Enter a table name to retrieve and display the schema details of that table.

Kafka Tab: Input the Kafka topic and Snowflake table name, and the app will start consuming Kafka messages and insert them into Snowflake.
=========================================================================================================
## 4. Code Overview
1. Generative AI Integration:
The app utilizes Google Gemini API to generate SQL queries based on user input. The configuration includes safety settings to block harmful content.
2. Snowflake Interaction:
The app connects to Snowflake using the snowflake-connector-python and snowflake-snowpark libraries.
Fetches table details using the DESC TABLE command and executes custom queries generated by Gemini.
Inserts data into Snowflake tables using session.write_pandas.
3. Kafka Integration:
The app consumes data from a Kafka topic using confluent_kafka.Consumer.
It validates the incoming data to ensure it follows the correct format before inserting it into Snowflake.
4. Error Handling and Logging:
Invalid data is logged to a CSV file (invalid_records.csv) for future inspection.
Errors related to data insertion or message consumption are displayed in the app interface.
5. Data Validation:
Incoming Kafka records are validated for data types (e.g., ensuring VOLUME is an integer, and OPENING_PRICE and MARKET_CAP are floats or integers).
=========================================================================================================
## 5 . Example Workflow
User enters a query in the "Query Data" tab.
Generative AI (Gemini) generates an SQL query based on the input.
The app fetches data from Snowflake based on the generated SQL query.
The results are displayed in a tabular format, and users can select a chart type for visualization.

Kafka consumption: The app listens to the specified Kafka topic and inserts the data into Snowflake after validation.
=========================================================================================================
## 6. Kafka 

Create Topic
----------
.\bin\kafka-topics.sh --create --topic test --bootstrap-server localhost:9092

Zookeeper and Kafka server start
-----------------------------------
.\bin\windows\zookeeper-server-start.bat .\config\zk.properties
.\bin\windows\kafka-server-start.bat .\config\server.properties

Producer
-----------
.\bin\kafka-console-producer.sh --topic test --bootstrap-server localhost:9092
